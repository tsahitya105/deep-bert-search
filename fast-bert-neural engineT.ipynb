{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:14:14.241067Z",
     "start_time": "2021-08-01T06:14:04.802634Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:14:02.173688Z",
     "start_time": "2021-08-01T06:13:57.406Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install gensim\n",
    "!pip install nltk\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:14:14.319943Z",
     "start_time": "2021-08-01T06:14:14.244954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:14:17.646247Z",
     "start_time": "2021-08-01T06:14:14.321944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from gensim.models.fasttext import FastText\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import WordPunctTokenizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"sentences-how2-ted.txt\"\n",
    "dataset=[]\n",
    "with open(filepath,encoding=\"utf8\") as fp:\n",
    "    for cnt, line in enumerate(fp):\n",
    "        dataset.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1457046"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(document):\n",
    "        # Remove all the special characters\n",
    "        document = re.sub(r'\\W', ' ', str(document))\n",
    "\n",
    "        # remove all single characters\n",
    "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "        # Remove single characters from the start\n",
    "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "        # Removing prefixed 'b'\n",
    "        document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "        # Converting to Lowercase\n",
    "        document = document.lower()\n",
    "\n",
    "        # Lemmatization\n",
    "        tokens = document.split()\n",
    "        tokens = [stemmer.lemmatize(word) for word in tokens]\n",
    "        tokens = [word for word in tokens if word not in en_stop]\n",
    "        tokens = [word for word in tokens if len(word) > 3]\n",
    "\n",
    "        preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "        return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'live looping number'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dataset=[]\n",
    "for data in dataset:\n",
    "    preprocessed_dataset.append(preprocess_text(data))\n",
    "preprocessed_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_punctuation_tokenizer = nltk.WordPunctTokenizer()\n",
    "word_tokenized_corpus = [word_punctuation_tokenizer.tokenize(sent) for sent in preprocessed_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = #add\n",
    "window_size = 60\n",
    "min_word = 5\n",
    "down_sampling = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FastText(word_tokenized_corpus,\n",
    "                      vector_size=embedding_size,\n",
    "                      window=window_size,\n",
    "                      min_count=min_word,\n",
    "                      sample=down_sampling,\n",
    "                      sg=1,\n",
    "                      epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save(\"ft3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.11867094e-02  1.86043277e-01  7.42172718e-01  7.03170657e-01\n",
      "  1.84241667e-01  1.77577928e-01 -1.01394676e-01  3.37691307e-01\n",
      " -1.13134025e-04  1.63667247e-01 -4.41160411e-01 -2.67293662e-01\n",
      "  2.23436460e-01  4.09761816e-01  3.82486105e-01 -4.43094164e-01\n",
      "  6.52074441e-02 -1.05362438e-01 -3.45348120e-01  4.23268169e-01\n",
      " -1.41448453e-01 -1.35518909e-01  1.83118798e-03  1.89384490e-01\n",
      " -5.28928876e-01 -1.60421446e-01 -2.80827761e-01  1.36411354e-01\n",
      " -6.83990240e-01 -1.38564497e-01  2.42841363e-01 -2.24119768e-01\n",
      "  8.81111249e-02  3.67523491e-01 -7.95679167e-03  2.76266754e-01\n",
      " -2.39378273e-01  4.83932853e-01  2.51949906e-01 -7.62978271e-02\n",
      "  6.08546615e-01  5.25602698e-01 -1.60130143e-01  4.17516045e-02\n",
      " -3.60972015e-04 -8.23773503e-01 -5.64213932e-01 -1.50488928e-01\n",
      "  6.96438611e-01 -5.98508418e-01  1.61758408e-01 -5.24430037e-01\n",
      " -3.10293704e-01  2.12354735e-01  1.27375141e-01 -2.04908147e-01\n",
      " -5.04954875e-01 -2.60780096e-01  6.30348027e-01 -2.17022020e-02\n",
      " -1.79616883e-01 -9.38433856e-02 -4.76621062e-01  4.61349994e-01\n",
      " -1.54604733e-01  2.51050711e-01 -3.67824793e-01 -5.14297962e-01\n",
      "  5.65730870e-01 -1.58903152e-01  2.45930534e-02  1.74205497e-01\n",
      "  5.95693529e-01 -3.50103229e-01  7.37316608e-02  4.05591875e-02\n",
      " -3.97089481e-01  2.44578719e-01  3.87432188e-01  3.07653964e-01\n",
      "  2.89344043e-01  5.75989187e-01  7.86643177e-02  4.34843719e-01\n",
      " -3.75105828e-01  4.20464203e-02 -2.18038410e-01  3.34846020e-01\n",
      " -5.12790799e-01 -1.66744277e-01 -5.65954149e-01 -7.22777545e-02\n",
      " -6.82071373e-02  5.30256569e-01  1.29913434e-01  4.56560373e-01\n",
      " -6.65444806e-02  5.17679751e-01 -8.27075124e-01 -7.72038922e-02]\n"
     ]
    }
   ],
   "source": [
    "print(ft_model.wv['guitar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:14:26.697240Z",
     "start_time": "2021-08-01T06:14:26.680221Z"
    }
   },
   "outputs": [],
   "source": [
    "def l2_norm(x):\n",
    "    return np.sqrt(np.sum(x**2))\n",
    "\n",
    "def div_norm(x):\n",
    "    norm_value = l2_norm(x)\n",
    "    if norm_value > 0:\n",
    "        return x * ( 1.0 / norm_value)\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def getSentenceEmbedding(sent, model):\n",
    "    sentArr=sent.split(\" \")\n",
    "    start = np.zeros(embedding_size)\n",
    "    for word in sentArr:\n",
    "        word_embed=model.wv[word]\n",
    "        start+=div_norm(word_embed)\n",
    "    return start/len(sentArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:14:30.532685Z",
     "start_time": "2021-08-01T06:14:27.480272Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import gensim\n",
    "ft_model = gensim.models.Word2Vec.load(\"ft3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:14:32.829231Z",
     "start_time": "2021-08-01T06:14:31.532666Z"
    }
   },
   "outputs": [],
   "source": [
    "# from gensim.test.utils import get_tmpfile\n",
    "# fname = get_tmpfile(\"fasttext.model\")\n",
    "from gensim.models.fasttext import save_facebook_model\n",
    "save_facebook_model(ft_model,'fin-how2-ted.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:14:33.922265Z",
     "start_time": "2021-08-01T06:14:33.902300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817872119129996"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "embedding_size = 100\n",
    "\n",
    "dataSetI = getSentenceEmbedding('guitar band is the best',ft_model)\n",
    "dataSetII = getSentenceEmbedding('greatest is keyboard',ft_model)\n",
    "result = 1 - spatial.distance.cosine(dataSetI, dataSetII)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:14:35.212910Z",
     "start_time": "2021-08-01T06:14:35.200899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04227039, -0.03386529,  0.07325236,  0.13295032,  0.0443842 ,\n",
       "       -0.02359397,  0.05852209,  0.10887032, -0.06570284,  0.07415543,\n",
       "        0.05682793, -0.03411683, -0.01336634,  0.05113566,  0.10229225,\n",
       "       -0.04903141,  0.03347905, -0.02948182, -0.02433966,  0.02586864,\n",
       "        0.01016971, -0.01023666, -0.00227027, -0.03857789, -0.0678262 ,\n",
       "       -0.00674218,  0.00806346, -0.01471914,  0.04604813, -0.02843316,\n",
       "        0.08069926, -0.10594295,  0.01452547,  0.05773231,  0.05502658,\n",
       "        0.01263518, -0.0611342 ,  0.14831504,  0.03152205, -0.03683632,\n",
       "        0.18366763,  0.09046039, -0.03892249, -0.0090938 ,  0.01456011,\n",
       "       -0.04382349, -0.12949245,  0.03875612,  0.13270901, -0.15601999,\n",
       "       -0.0103946 , -0.08027773, -0.06894502, -0.00740602,  0.02639393,\n",
       "        0.03731535, -0.06576446, -0.00416651,  0.01303254, -0.01887212,\n",
       "        0.012701  ,  0.00915757, -0.08566835,  0.06069303, -0.05254422,\n",
       "        0.08445841, -0.0631744 , -0.09041692,  0.04213962, -0.04328199,\n",
       "        0.03447777, -0.0179259 ,  0.05848085, -0.09899947,  0.04555237,\n",
       "        0.02100639, -0.0745653 ,  0.03161739,  0.1446725 ,  0.08672507,\n",
       "       -0.01422694,  0.10418183,  0.04674912, -0.00820862, -0.13402325,\n",
       "        0.01900219, -0.04536138,  0.03959833, -0.03833206,  0.03605885,\n",
       "       -0.08532397,  0.02868024, -0.05004452,  0.08765104,  0.03055901,\n",
       "        0.02614323, -0.00227775,  0.10694374, -0.12242307,  0.01672169])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSentenceEmbedding('guitar band is the best',ft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sentence BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:16:13.966072Z",
     "start_time": "2021-08-01T06:16:12.357851Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('msmarco-distilbert-base-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:16:15.477489Z",
     "start_time": "2021-08-01T06:16:15.363494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.3798\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: 0.1831\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.7922\n"
     ]
    }
   ],
   "source": [
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:16:16.107076Z",
     "start_time": "2021-08-01T06:16:16.096084Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFasttextScore(sent1,query):\n",
    "    dataSetI = getSentenceEmbedding(sent1,ft_model)\n",
    "    dataSetII = getSentenceEmbedding(query,ft_model)\n",
    "    result = 1 - spatial.distance.cosine(dataSetI, dataSetII)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:16:16.890469Z",
     "start_time": "2021-08-01T06:16:16.875444Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBertScore(sent1,query):\n",
    "    embeddings1 = model.encode([sent1], convert_to_tensor=True)\n",
    "    embeddings2 = model.encode([query], convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return cosine_scores[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:16:17.422983Z",
     "start_time": "2021-08-01T06:16:17.410411Z"
    }
   },
   "outputs": [],
   "source": [
    "def getNeuralScore(sent1,query):\n",
    "    ft_score=getFasttextScore(sent1,query)\n",
    "    print(\"Fastext score: \"+str(ft_score))\n",
    "    bert_score=getBertScore(sent1,query).item()\n",
    "    print(\"Bert score: \"+str(bert_score))\n",
    "    return max(0.5*bert_score+0.7*ft_score,max(ft_score,bert_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:16:20.124492Z",
     "start_time": "2021-08-01T06:16:20.043438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastext score: 0.8335180593766575\n",
      "Bert score: 0.4331139028072357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8335180593766575"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNeuralScore(\"The new movie is awesome\",\"the picture is amazing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:16:20.773633Z",
     "start_time": "2021-08-01T06:16:20.699515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastext score: 1.0\n",
      "Bert score: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNeuralScore(\"best movie ever\",\"best movie ever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:16:42.594603Z",
     "start_time": "2021-08-01T06:16:42.534539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastext score: 0.739302830330023\n",
      "Bert score: 0.5262815356254578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7806527490437449"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNeuralScore(\"batman is superhero\",\"joker is villain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T06:16:43.584094Z",
     "start_time": "2021-08-01T06:16:43.522575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastext score: 0.5079720996919435\n",
      "Bert score: 0.33791279792785645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5245368687482886"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNeuralScore(\"The movie is a cinematic masterpiece\",\"amazing picture quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastext score: 0.7170005066107702\n",
      "Bert score: 0.47804051637649536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7170005066107702"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNeuralScore(\"greek salad\",\"chicken fried rice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastext score: 0.4711424784903667\n",
      "Bert score: 0.2975931763648987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4711424784903667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNeuralScore(\"I hate my life\",\"feeling depressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastext score: 0.5894486504703984\n",
      "Bert score: 0.2746565043926239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5894486504703984"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNeuralScore(\"I hate my life\",\"Life is beautiful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastext score: 0.45843633198155986\n",
      "Bert score: 0.3202257454395294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45843633198155986"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNeuralScore(\"The movie is a cinematic masterpice\",\"amazing picture quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastext score: 0.5818073003356188\n",
      "Bert score: 0.6666767001152039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666767001152039"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNeuralScore(\"The movie is a cinematic masterpiece\",\"I love this film\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastext score: 0.44814715896312673\n",
      "Bert score: 0.15816974639892578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44814715896312673"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNeuralScore(\"bookish knowledge\",\"flowers and petals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
